{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Python Tutorial – How to Scrape Data From A Website\n",
    "\n",
    "Python is a beautiful language to code in. It has a great package ecosystem, there's much less noise than you'll find in other languages, and it is super easy to use.\n",
    "\n",
    "Python is used for a number of things, from data analysis to server programming. And one exciting use-case of Python is Web Scraping.\n",
    "\n",
    "In this article, we will cover how to use Python for web scraping. We'll also work through a complete hands-on classroom guide as we proceed.\n",
    "\n",
    "*Note: We will be scraping a webpage that I host, so we can safely learn scraping on it. Many companies do not allow scraping on their websites, so this is a good way to learn. Just make sure to check before you scrape.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load webpages in Python with 'request'\n",
    "\n",
    "Welcome to a new classroom! Let’s start our first lab in the classroom by learning about the request module in Python.\n",
    "\n",
    "The `requests` module allows you to send HTTP requests using Python.\n",
    "\n",
    "The HTTP request returns a Response Object with all the response data (content, encoding, status, etc). One example of getting the HTML of a page:\n",
    "\n",
    "----\n",
    "```python\n",
    "import requests\n",
    "\n",
    "res = requests.get('URL')\n",
    "\n",
    "print(res.text)\n",
    "print(res.status_code)\n",
    "```\n",
    "----\n",
    "To pass this lab, take care of the following things:\n",
    "\n",
    "1. Get the contents of the following URL using `requests` module: **https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/**\n",
    "2. Store the text response (as shown above) in a variable called `txt`\n",
    "3. Store the status code (as shown above) in a variable called `status`\n",
    "4. Print `txt` and `status` using `print` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/')\n",
    "\n",
    "txt = response.text\n",
    "status = response.status_code\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\t<head>\n",
      "\t\t<!-- Anti-flicker snippet (recommended)  -->\n",
      "\t\t<style>\n",
      "\t\t\t.async-hide {\n",
      "\t\t\t\topacity: 0 !important;\n",
      "\t\t\t}\n",
      "\t\t</style>\n",
      "\t\t<title>codedamn Web Scraper demo</title>\n",
      "\t\t<meta charset=\"utf-8\" />\n",
      "\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n",
      "\n",
      "\t\t<meta\n",
      "\t\t\tname=\"keywords\"\n",
      "\t\t\tcontent=\"web scraping,Web Scraper,Chrome extension,Crawling,Cross platform scraper, \"\n",
      "\t\t/>\n",
      "\t\t<meta name=\"description\" content=\"The most popular web scraping website.\" />\n",
      "\t\t<link\n",
      "\t\t\trel=\"icon\"\n",
      "\t\t\tsizes=\"128x128\"\n",
      "\t\t\thref=\"/webscraper-python-codedamn-classroom-website/favicon.png\"\n",
      "\t\t/>\n",
      "\n",
      "\t\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
      "\n",
      "\t\t<link rel=\"stylesheet\" href=\"/webscraper-python-codedamn-classroom-website/app.css\" />\n",
      "\n",
      "\t\t<link\n",
      "\t\t\trel=\"apple-touch-icon\"\n",
      "\t\t\thref=\"/webscraper-python-codedamn-classroom-website/logo-icon.png\"\n",
      "\t\t/>\n",
      "\n",
      "\t\t<script defer src=\"/webscraper-python-codedamn-classroom-website/app.js\"></script>\n",
      "\t</head>\n",
      "\t<body>\n",
      "\t\t<header role=\"banner\" class=\"navbar navbar-fixed-top navbar-static\">\n",
      "\t\t\t<div class=\"container\">\n",
      "\t\t\t\t<div class=\"navbar-header\">\n",
      "\t\t\t\t\t<a\n",
      "\t\t\t\t\t\tdata-toggle=\"collapse-side\"\n",
      "\t\t\t\t\t\tdata-target=\".side-collapse\"\n",
      "\t\t\t\t\t\tdata-target-2=\".side-collapse-container\"\n",
      "\t\t\t\t\t>\n",
      "\t\t\t\t\t\t<button\n",
      "\t\t\t\t\t\t\ttype=\"button\"\n",
      "\t\t\t\t\t\t\tclass=\"navbar-toggle pull-right collapsed\"\n",
      "\t\t\t\t\t\t\tdata-toggle=\"collapse\"\n",
      "\t\t\t\t\t\t\tdata-target=\"#navbar\"\n",
      "\t\t\t\t\t\t\tdata-target-2=\".side-collapse-container\"\n",
      "\t\t\t\t\t\t\tdata-target-3=\".side-collapse\"\n",
      "\t\t\t\t\t\t\taria-expanded=\"false\"\n",
      "\t\t\t\t\t\t\taria-controls=\"navbar\"\n",
      "\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t<span class=\"sr-only\">Toggle navigation</span>\n",
      "\t\t\t\t\t\t\t<span class=\"icon-bar top-bar\"></span>\n",
      "\t\t\t\t\t\t\t<span class=\"icon-bar middle-bar\"></span>\n",
      "\t\t\t\t\t\t\t<span class=\"icon-bar bottom-bar\"></span>\n",
      "\t\t\t\t\t\t</button>\n",
      "\t\t\t\t\t</a>\n",
      "\t\t\t\t\t<div class=\"navbar-brand\">\n",
      "\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/\"\n",
      "\t\t\t\t\t\t\t><img\n",
      "\t\t\t\t\t\t\t\tsrc=\"/webscraper-python-codedamn-classroom-website/logo_white.svg\"\n",
      "\t\t\t\t\t\t\t\talt=\"Web Scraper\"\n",
      "\t\t\t\t\t\t/></a>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t</div>\n",
      "\n",
      "\t\t\t\t<div class=\"side-collapse in\">\n",
      "\t\t\t\t\t<nav id=\"navbar\" role=\"navigation\" class=\"navbar-collapse collapse\">\n",
      "\t\t\t\t\t\t<ul class=\"nav navbar-nav navbar-right\">\n",
      "\t\t\t\t\t\t\t<li class=\"hidden\">\n",
      "\t\t\t\t\t\t\t\t<a href=\"#page-top\"></a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/\"\n",
      "\t\t\t\t\t\t\t\t\tclass=\"menuitm\"\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t<p>Web Scraper</p>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"crta\"></div>\n",
      "\t\t\t\t\t\t\t\t</a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/cloud-scraper\"\n",
      "\t\t\t\t\t\t\t\t\tclass=\"menuitm\"\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t<p>Cloud Scraper</p>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"crta\"></div>\n",
      "\t\t\t\t\t\t\t\t</a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/pricing\"\n",
      "\t\t\t\t\t\t\t\t\tclass=\"menuitm\"\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t<p>Pricing</p>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"crta\"></div>\n",
      "\t\t\t\t\t\t\t\t</a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\n",
      "\t\t\t\t\t\t\t<li class=\"dropdown\">\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"#section3\"\n",
      "\t\t\t\t\t\t\t\t\tclass=\"menuitm dropdown-toggle\"\n",
      "\t\t\t\t\t\t\t\t\tdata-toggle=\"dropdown\"\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t<p>Learn</p>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"crta\"></div>\n",
      "\t\t\t\t\t\t\t\t</a>\n",
      "\t\t\t\t\t\t\t\t<ul class=\"dropdown-menu\">\n",
      "\t\t\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/documentation\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t>Documentation</a\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/tutorials\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t>Video Tutorials</a\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/how-to-videos\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t>How to</a\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/test-sites\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t>Test Sites</a\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"https://forum.webscraper.io/\"\n",
      "\t\t\t\t\t\t\t\t\t\t\ttarget=\"_blank\"\n",
      "\t\t\t\t\t\t\t\t\t\t\trel=\"noopener\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t>Forum</a\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\ttarget=\"_blank\"\n",
      "\t\t\t\t\t\t\t\t\thref=\"https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn?hl=en\"\n",
      "\t\t\t\t\t\t\t\t\tclass=\"btn-menu1 install-extension\"\n",
      "\t\t\t\t\t\t\t\t\trel=\"noopener\"\n",
      "\t\t\t\t\t\t\t\t\t>Install</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"https://cloud.webscraper.io/\" class=\"btn-menu2\">Login</a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t</nav>\n",
      "\t\t\t\t</div>\n",
      "\t\t\t</div>\n",
      "\t\t</header>\n",
      "\n",
      "\t\t<div class=\"wrapper\">\n",
      "\t\t\t<div class=\"formenu-here container-fluid\"></div>\n",
      "\t\t\t<div class=\"container-fluid blog-hero\">\n",
      "\t\t\t\t<div class=\"container\">\n",
      "\t\t\t\t\t<div class=\"row\">\n",
      "\t\t\t\t\t\t<div class=\"col-md-12\">\n",
      "\t\t\t\t\t\t\t<h1>Test Sites</h1>\n",
      "\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t</div>\n",
      "\t\t\t</div>\n",
      "\n",
      "\t\t\t<div class=\"container test-site\">\n",
      "\t\t\t\t<div class=\"row\">\n",
      "\t\t\t\t\t<div class=\"col-md-3 sidebar\">\n",
      "\t\t\t\t\t\t<div class=\"navbar-default sidebar\" role=\"navigation\">\n",
      "\t\t\t\t\t\t\t<div class=\"sidebar-nav navbar-collapse\">\n",
      "\t\t\t\t\t\t\t\t<ul class=\"nav\" id=\"side-menu\">\n",
      "\t\t\t\t\t\t\t\t\t<li class=\"active\">\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t>Home</a\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/computers\"\n",
      "\t\t\t\t\t\t\t\t\t\t\tclass=\"category-link\"\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t\t\tComputers\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"fa arrow\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t</a>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/phones\"\n",
      "\t\t\t\t\t\t\t\t\t\t\tclass=\"category-link\"\n",
      "\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t\t\tPhones\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"fa arrow\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t</a>\n",
      "\t\t\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t\t<div class=\"col-md-9\">\n",
      "\t\t\t\t\t\t<div class=\"jumbotron\">\n",
      "\t\t\t\t\t\t\t<h1>E-commerce training site</h1>\n",
      "\t\t\t\t\t\t\t<p>\n",
      "\t\t\t\t\t\t\t\tWelcome to WebScraper e-commerce site. You can use this site for\n",
      "\t\t\t\t\t\t\t\ttraining to learn how to use the Web Scraper. Items listed here are\n",
      "\t\t\t\t\t\t\t\tnot for sale.\n",
      "\t\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t\t</div>\n",
      "\n",
      "\t\t\t\t\t\t<h2>Top items being scraped right now</h2>\n",
      "\n",
      "\t\t\t\t\t\t<div class=\"row\">\n",
      "\t\t\t\t\t\t\t<div class=\"col-sm-4 col-lg-4 col-md-4\">\n",
      "\t\t\t\t\t\t\t\t<div class=\"thumbnail\">\n",
      "\t\t\t\t\t\t\t\t\t<img\n",
      "\t\t\t\t\t\t\t\t\t\tclass=\"img-responsive\"\n",
      "\t\t\t\t\t\t\t\t\t\talt=\"item\"\n",
      "\t\t\t\t\t\t\t\t\t\tsrc=\"/webscraper-python-codedamn-classroom-website/cart2.png\"\n",
      "\t\t\t\t\t\t\t\t\t/>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"caption\">\n",
      "\t\t\t\t\t\t\t\t\t\t<h4 class=\"pull-right price\">$1139.54</h4>\n",
      "\t\t\t\t\t\t\t\t\t\t<h4>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/593\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tclass=\"title\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\ttitle=\"Asus AsusPro Advanced BU401LA-FA271G Dark Grey\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t>Asus AsusPro Adv...</a\n",
      "\t\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t\t</h4>\n",
      "\t\t\t\t\t\t\t\t\t\t<p class=\"description\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tAsus AsusPro Advanced BU401LA-FA271G Dark Grey,\n",
      "\t\t\t\t\t\t\t\t\t\t\t14&quot;, Core i5-4210U, 4GB, 128GB SSD, Win7 Pro 64bit,\n",
      "\t\t\t\t\t\t\t\t\t\t\tENG\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"ratings\">\n",
      "\t\t\t\t\t\t\t\t\t\t<p class=\"pull-right\">7 reviews</p>\n",
      "\t\t\t\t\t\t\t\t\t\t<p data-rating=\"3\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t<div class=\"col-sm-4 col-lg-4 col-md-4\">\n",
      "\t\t\t\t\t\t\t\t<div class=\"thumbnail\">\n",
      "\t\t\t\t\t\t\t\t\t<img\n",
      "\t\t\t\t\t\t\t\t\t\tclass=\"img-responsive\"\n",
      "\t\t\t\t\t\t\t\t\t\talt=\"item\"\n",
      "\t\t\t\t\t\t\t\t\t\tsrc=\"/webscraper-python-codedamn-classroom-website/cart2.png\"\n",
      "\t\t\t\t\t\t\t\t\t/>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"caption\">\n",
      "\t\t\t\t\t\t\t\t\t\t<h4 class=\"pull-right price\">$1101.83</h4>\n",
      "\t\t\t\t\t\t\t\t\t\t<h4>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/583\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tclass=\"title\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\ttitle=\"Asus ROG Strix GL553VD-DM535T\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t>Asus ROG Strix G...</a\n",
      "\t\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t\t</h4>\n",
      "\t\t\t\t\t\t\t\t\t\t<p class=\"description\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tApple MacBook Air 13.3&quot;, Core i5 1.8GHz, 8GB, 128GB\n",
      "\t\t\t\t\t\t\t\t\t\t\tSSD, Intel HD 4000, RUS\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"ratings\">\n",
      "\t\t\t\t\t\t\t\t\t\t<p class=\"pull-right\">4 reviews</p>\n",
      "\t\t\t\t\t\t\t\t\t\t<p data-rating=\"2\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t<div class=\"col-sm-4 col-lg-4 col-md-4\">\n",
      "\t\t\t\t\t\t\t\t<div class=\"thumbnail\">\n",
      "\t\t\t\t\t\t\t\t\t<img\n",
      "\t\t\t\t\t\t\t\t\t\tclass=\"img-responsive\"\n",
      "\t\t\t\t\t\t\t\t\t\talt=\"item\"\n",
      "\t\t\t\t\t\t\t\t\t\tsrc=\"/webscraper-python-codedamn-classroom-website/cart2.png\"\n",
      "\t\t\t\t\t\t\t\t\t/>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"caption\">\n",
      "\t\t\t\t\t\t\t\t\t\t<h4 class=\"pull-right price\">$494.71</h4>\n",
      "\t\t\t\t\t\t\t\t\t\t<h4>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/576\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tclass=\"title\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\ttitle=\"Acer Aspire 3 A315-51 Black\"\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t>Acer Aspire 3 A3...</a\n",
      "\t\t\t\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t\t\t\t</h4>\n",
      "\t\t\t\t\t\t\t\t\t\t<p class=\"description\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tAcer Aspire 3 A315-51 Black, 15.6&quot; FHD, Core\n",
      "\t\t\t\t\t\t\t\t\t\t\ti3-7100U, 4GB, 500GB + 128GB SSD, Windows 10 Home\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t\t\t<div class=\"ratings\">\n",
      "\t\t\t\t\t\t\t\t\t\t<p class=\"pull-right\">2 reviews</p>\n",
      "\t\t\t\t\t\t\t\t\t\t<p data-rating=\"4\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"glyphicon glyphicon-star\"></span>\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t\t</div>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t</div>\n",
      "\t\t\t</div>\n",
      "\t\t\t<div class=\"clearfix\"></div>\n",
      "\t\t\t<div class=\"push\"></div>\n",
      "\t\t</div>\n",
      "\n",
      "\t\t<div class=\"container-fluid footer\" id=\"layout-footer\">\n",
      "\t\t\t<div class=\"container\">\n",
      "\t\t\t\t<div class=\"row\">\n",
      "\t\t\t\t\t<div class=\"col-md-3\">\n",
      "\t\t\t\t\t\t<ul>\n",
      "\t\t\t\t\t\t\t<li><p>Products</p></li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/\"\n",
      "\t\t\t\t\t\t\t\t\t>Web Scraper browser extension</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/pricing\"\n",
      "\t\t\t\t\t\t\t\t\t>Web Scraper Cloud</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t\t<div class=\"col-md-3\">\n",
      "\t\t\t\t\t\t<ul>\n",
      "\t\t\t\t\t\t\t<li><p>Company</p></li>\n",
      "\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/contact\"\n",
      "\t\t\t\t\t\t\t\t\t>Contact</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/privacy-policy\"\n",
      "\t\t\t\t\t\t\t\t\t>Website Privacy Policy</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/extension-privacy-policy\"\n",
      "\t\t\t\t\t\t\t\t\t>Browser Extension Privacy Policy</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"http://webscraperio.us-east-1.elasticbeanstalk.com/downloads/Web_Scraper_Media_Kit.zip\"\n",
      "\t\t\t\t\t\t\t\t\t>Media kit</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/jobs\"\n",
      "\t\t\t\t\t\t\t\t\t>Jobs</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t\t<div class=\"col-md-3\">\n",
      "\t\t\t\t\t\t<ul>\n",
      "\t\t\t\t\t\t\t<li><p>Resources</p></li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/blog\"\n",
      "\t\t\t\t\t\t\t\t\t>Blog</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"/webscraper-python-codedamn-classroom-website/documentation\"\n",
      "\t\t\t\t\t\t\t\t\t>Documentation</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/tutorials\"\n",
      "\t\t\t\t\t\t\t\t\t>Video Tutorials</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/screenshots\"\n",
      "\t\t\t\t\t\t\t\t\t>Screenshots</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"/webscraper-python-codedamn-classroom-website/test-sites\"\n",
      "\t\t\t\t\t\t\t\t\t>Test Sites</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\ttarget=\"_blank\"\n",
      "\t\t\t\t\t\t\t\t\thref=\"https://forum.webscraper.io/\"\n",
      "\t\t\t\t\t\t\t\t\trel=\"noopener\"\n",
      "\t\t\t\t\t\t\t\t\t>Forum</a\n",
      "\t\t\t\t\t\t\t\t>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t\t<div class=\"col-md-3\">\n",
      "\t\t\t\t\t\t<ul>\n",
      "\t\t\t\t\t\t\t<li><p>CONTACT US</p></li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a href=\"mailto:info@webscraper.io\">info@webscraper.io</a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\tRupniecibas iela 30,<br />\n",
      "\t\t\t\t\t\t\t\tRiga, Latvia, LV-1045\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t\t<ul class=\"smedia\">\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"https://www.facebook.com/webscraperio/\"\n",
      "\t\t\t\t\t\t\t\t\ttarget=\"_blank\"\n",
      "\t\t\t\t\t\t\t\t\trel=\"noopener\"\n",
      "\t\t\t\t\t\t\t\t\t><img\n",
      "\t\t\t\t\t\t\t\t\t\tsrc=\"/webscraper-python-codedamn-classroom-website/fbicon.png\"\n",
      "\t\t\t\t\t\t\t\t\t\talt=\"Web Scraper on Facebook\"\n",
      "\t\t\t\t\t\t\t\t/></a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t\t<li>\n",
      "\t\t\t\t\t\t\t\t<a\n",
      "\t\t\t\t\t\t\t\t\thref=\"https://twitter.com/webscraperio\"\n",
      "\t\t\t\t\t\t\t\t\ttarget=\"_blank\"\n",
      "\t\t\t\t\t\t\t\t\trel=\"noopener\"\n",
      "\t\t\t\t\t\t\t\t\t><img\n",
      "\t\t\t\t\t\t\t\t\t\tsrc=\"/webscraper-python-codedamn-classroom-website/twicon.png\"\n",
      "\t\t\t\t\t\t\t\t\t\talt=\"Web Scraper on Twitter\"\n",
      "\t\t\t\t\t\t\t\t/></a>\n",
      "\t\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t\t</ul>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t</div>\n",
      "\t\t\t\t<div class=\"row\">\n",
      "\t\t\t\t\t<div class=\"col-md-12\">\n",
      "\t\t\t\t\t\t<p class=\"copyright\">\n",
      "\t\t\t\t\t\t\tCopyright &copy 2020 <a href=\"#\">Web Scraper</a> | All rights reserved |\n",
      "\t\t\t\t\t\t\tRemixed by codedamn\n",
      "\t\t\t\t\t\t</p>\n",
      "\t\t\t\t\t</div>\n",
      "\t\t\t\t</div>\n",
      "\t\t\t</div>\n",
      "\t\t</div>\n",
      "\t</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting title with BeautifulSoup\n",
    "\n",
    "In this whole classroom, we’ll be using a library called `BeautifulSoup` in python to do web scraping. Beautiful Soup is a Python library designed for quick turnaround projects like screen-scraping. Three features make it powerful:\n",
    "\n",
    "1. Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree: a toolkit for dissecting a document and extracting what you need. It doesn't take much code to write an application\n",
    "2. Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8. You don't have to think about encodings unless the document doesn't specify an encoding and Beautiful Soup can't detect one. Then you just have to specify the original encoding.\n",
    "3. Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility.\n",
    "\n",
    "Beautiful Soup parses anything you give it, and does the tree traversal stuff for you. You can tell it \"Find all the links\", or \"Find all the links of class `externalLink`\", or \"Find all the links whose URLs match \"foo.com\", or \"Find the table heading that's got bold text, then give me that text.\"\n",
    "\n",
    "Here’s a simple example of BeautifulSoup:\n",
    "\n",
    "****\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"URL\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "title = soup.title.text # gets you the text of the <title>(...)</title>\n",
    "```\n",
    "****\n",
    "Remember how we loaded page content using `requests` module in the last lab? Similarly, we first download the page, and then load all the content into BeautifulSoup. Finally, we extract out the page title just by saying `soup.title`, very convenient!\n",
    "\n",
    "To pass this lab:\n",
    "\n",
    "1. Use `requests` package to get title of the URL:\n",
    "\n",
    "    https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\n",
    "\n",
    "2. Use BeautifulSoup to store the title of this page into a variable called `page_title`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codedamn Web Scraper demo\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "\n",
    "# Extract title of page\n",
    "page_title = soup.title.text\n",
    "\n",
    "# print the result\n",
    "print(page_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Soup-ed body and head\n",
    "\n",
    "In the last lab, we saw how we can extract `title` from the page. It is equally easy to extract out certain sections too. We also saw that you have to call `.text` on these to get the string, but you can print them without calling `.text` too, and it will give you the full markup. Try to run the example below:\n",
    "\n",
    "Let us take a look at how you can extract out `body` and `head` sections from your pages.\n",
    "\n",
    "****\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a request\n",
    "page = requests.get(\"url\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Extract title of page\n",
    "page_title = soup.title.text\n",
    "\n",
    "# Extract body of page\n",
    "page_body = soup.body\n",
    "\n",
    "# Extract head of page\n",
    "page_head = soup.head\n",
    "\n",
    "# print the result\n",
    "print(page_body, page_head)\n",
    "```\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>codedamn Web Scraper demo</title>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\n",
    "    \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Extract info of page\n",
    "page_title = soup.title\n",
    "page_body = soup.body\n",
    "page_head = soup.head\n",
    "\n",
    "# print the result\n",
    "print(page_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<header class=\"navbar navbar-fixed-top navbar-static\" role=\"banner\">\n",
      "<div class=\"container\">\n",
      "<div class=\"navbar-header\">\n",
      "<a data-target=\".side-collapse\" data-target-2=\".side-collapse-container\" data-toggle=\"collapse-side\">\n",
      "<button aria-controls=\"navbar\" aria-expanded=\"false\" class=\"navbar-toggle pull-right collapsed\" data-target=\"#navbar\" data-target-2=\".side-collapse-container\" data-target-3=\".side-collapse\" data-toggle=\"collapse\" type=\"button\">\n",
      "<span class=\"sr-only\">Toggle navigation</span>\n",
      "<span class=\"icon-bar top-bar\"></span>\n",
      "<span class=\"icon-bar middle-bar\"></span>\n",
      "<span class=\"icon-bar bottom-bar\"></span>\n",
      "</button>\n",
      "</a>\n",
      "<div class=\"navbar-brand\">\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/\"><img alt=\"Web Scraper\" src=\"/webscraper-python-codedamn-classroom-website/logo_white.svg\"/></a>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"side-collapse in\">\n",
      "<nav class=\"navbar-collapse collapse\" id=\"navbar\" role=\"navigation\">\n",
      "<ul class=\"nav navbar-nav navbar-right\">\n",
      "<li class=\"hidden\">\n",
      "<a href=\"#page-top\"></a>\n",
      "</li>\n",
      "<li>\n",
      "<a class=\"menuitm\" href=\"/webscraper-python-codedamn-classroom-website/\">\n",
      "<p>Web Scraper</p>\n",
      "<div class=\"crta\"></div>\n",
      "</a>\n",
      "</li>\n",
      "<li>\n",
      "<a class=\"menuitm\" href=\"/webscraper-python-codedamn-classroom-website/cloud-scraper\">\n",
      "<p>Cloud Scraper</p>\n",
      "<div class=\"crta\"></div>\n",
      "</a>\n",
      "</li>\n",
      "<li>\n",
      "<a class=\"menuitm\" href=\"/webscraper-python-codedamn-classroom-website/pricing\">\n",
      "<p>Pricing</p>\n",
      "<div class=\"crta\"></div>\n",
      "</a>\n",
      "</li>\n",
      "<li class=\"dropdown\">\n",
      "<a class=\"menuitm dropdown-toggle\" data-toggle=\"dropdown\" href=\"#section3\">\n",
      "<p>Learn</p>\n",
      "<div class=\"crta\"></div>\n",
      "</a>\n",
      "<ul class=\"dropdown-menu\">\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/documentation\">Documentation</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/tutorials\">Video Tutorials</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/how-to-videos\">How to</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/test-sites\">Test Sites</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"https://forum.webscraper.io/\" rel=\"noopener\" target=\"_blank\">Forum</a>\n",
      "</li>\n",
      "</ul>\n",
      "</li>\n",
      "<li>\n",
      "<a class=\"btn-menu1 install-extension\" href=\"https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn?hl=en\" rel=\"noopener\" target=\"_blank\">Install</a>\n",
      "</li>\n",
      "<li>\n",
      "<a class=\"btn-menu2\" href=\"https://cloud.webscraper.io/\">Login</a>\n",
      "</li>\n",
      "</ul>\n",
      "</nav>\n",
      "</div>\n",
      "</div>\n",
      "</header>\n",
      "<div class=\"wrapper\">\n",
      "<div class=\"formenu-here container-fluid\"></div>\n",
      "<div class=\"container-fluid blog-hero\">\n",
      "<div class=\"container\">\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-12\">\n",
      "<h1>Test Sites</h1>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"container test-site\">\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-3 sidebar\">\n",
      "<div class=\"navbar-default sidebar\" role=\"navigation\">\n",
      "<div class=\"sidebar-nav navbar-collapse\">\n",
      "<ul class=\"nav\" id=\"side-menu\">\n",
      "<li class=\"active\">\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone\">Home</a>\n",
      "</li>\n",
      "<li>\n",
      "<a class=\"category-link\" href=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/computers\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tComputers\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"fa arrow\"></span>\n",
      "</a>\n",
      "</li>\n",
      "<li>\n",
      "<a class=\"category-link\" href=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/phones\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tPhones\n",
      "\t\t\t\t\t\t\t\t\t\t\t<span class=\"fa arrow\"></span>\n",
      "</a>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"col-md-9\">\n",
      "<div class=\"jumbotron\">\n",
      "<h1>E-commerce training site</h1>\n",
      "<p>\n",
      "\t\t\t\t\t\t\t\tWelcome to WebScraper e-commerce site. You can use this site for\n",
      "\t\t\t\t\t\t\t\ttraining to learn how to use the Web Scraper. Items listed here are\n",
      "\t\t\t\t\t\t\t\tnot for sale.\n",
      "\t\t\t\t\t\t\t</p>\n",
      "</div>\n",
      "<h2>Top items being scraped right now</h2>\n",
      "<div class=\"row\">\n",
      "<div class=\"col-sm-4 col-lg-4 col-md-4\">\n",
      "<div class=\"thumbnail\">\n",
      "<img alt=\"item\" class=\"img-responsive\" src=\"/webscraper-python-codedamn-classroom-website/cart2.png\"/>\n",
      "<div class=\"caption\">\n",
      "<h4 class=\"pull-right price\">$1139.54</h4>\n",
      "<h4>\n",
      "<a class=\"title\" href=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/593\" title=\"Asus AsusPro Advanced BU401LA-FA271G Dark Grey\">Asus AsusPro Adv...</a>\n",
      "</h4>\n",
      "<p class=\"description\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tAsus AsusPro Advanced BU401LA-FA271G Dark Grey,\n",
      "\t\t\t\t\t\t\t\t\t\t\t14\", Core i5-4210U, 4GB, 128GB SSD, Win7 Pro 64bit,\n",
      "\t\t\t\t\t\t\t\t\t\t\tENG\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "</div>\n",
      "<div class=\"ratings\">\n",
      "<p class=\"pull-right\">7 reviews</p>\n",
      "<p data-rating=\"3\">\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"col-sm-4 col-lg-4 col-md-4\">\n",
      "<div class=\"thumbnail\">\n",
      "<img alt=\"item\" class=\"img-responsive\" src=\"/webscraper-python-codedamn-classroom-website/cart2.png\"/>\n",
      "<div class=\"caption\">\n",
      "<h4 class=\"pull-right price\">$1101.83</h4>\n",
      "<h4>\n",
      "<a class=\"title\" href=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/583\" title=\"Asus ROG Strix GL553VD-DM535T\">Asus ROG Strix G...</a>\n",
      "</h4>\n",
      "<p class=\"description\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tApple MacBook Air 13.3\", Core i5 1.8GHz, 8GB, 128GB\n",
      "\t\t\t\t\t\t\t\t\t\t\tSSD, Intel HD 4000, RUS\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "</div>\n",
      "<div class=\"ratings\">\n",
      "<p class=\"pull-right\">4 reviews</p>\n",
      "<p data-rating=\"2\">\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"col-sm-4 col-lg-4 col-md-4\">\n",
      "<div class=\"thumbnail\">\n",
      "<img alt=\"item\" class=\"img-responsive\" src=\"/webscraper-python-codedamn-classroom-website/cart2.png\"/>\n",
      "<div class=\"caption\">\n",
      "<h4 class=\"pull-right price\">$494.71</h4>\n",
      "<h4>\n",
      "<a class=\"title\" href=\"/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/576\" title=\"Acer Aspire 3 A315-51 Black\">Acer Aspire 3 A3...</a>\n",
      "</h4>\n",
      "<p class=\"description\">\n",
      "\t\t\t\t\t\t\t\t\t\t\tAcer Aspire 3 A315-51 Black, 15.6\" FHD, Core\n",
      "\t\t\t\t\t\t\t\t\t\t\ti3-7100U, 4GB, 500GB + 128GB SSD, Windows 10 Home\n",
      "\t\t\t\t\t\t\t\t\t\t</p>\n",
      "</div>\n",
      "<div class=\"ratings\">\n",
      "<p class=\"pull-right\">2 reviews</p>\n",
      "<p data-rating=\"4\">\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "<span class=\"glyphicon glyphicon-star\"></span>\n",
      "</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"clearfix\"></div>\n",
      "<div class=\"push\"></div>\n",
      "</div>\n",
      "<div class=\"container-fluid footer\" id=\"layout-footer\">\n",
      "<div class=\"container\">\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-3\">\n",
      "<ul>\n",
      "<li><p>Products</p></li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/\">Web Scraper browser extension</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/pricing\">Web Scraper Cloud</a>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"col-md-3\">\n",
      "<ul>\n",
      "<li><p>Company</p></li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/contact\">Contact</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/privacy-policy\">Website Privacy Policy</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/extension-privacy-policy\">Browser Extension Privacy Policy</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"http://webscraperio.us-east-1.elasticbeanstalk.com/downloads/Web_Scraper_Media_Kit.zip\">Media kit</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/jobs\">Jobs</a>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"col-md-3\">\n",
      "<ul>\n",
      "<li><p>Resources</p></li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/blog\">Blog</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/documentation\">Documentation</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/tutorials\">Video Tutorials</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/screenshots\">Screenshots</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"/webscraper-python-codedamn-classroom-website/test-sites\">Test Sites</a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"https://forum.webscraper.io/\" rel=\"noopener\" target=\"_blank\">Forum</a>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"col-md-3\">\n",
      "<ul>\n",
      "<li><p>CONTACT US</p></li>\n",
      "<li>\n",
      "<a href=\"mailto:info@webscraper.io\">info@webscraper.io</a>\n",
      "</li>\n",
      "<li>\n",
      "\t\t\t\t\t\t\t\tRupniecibas iela 30,<br/>\n",
      "\t\t\t\t\t\t\t\tRiga, Latvia, LV-1045\n",
      "\t\t\t\t\t\t\t</li>\n",
      "</ul>\n",
      "<ul class=\"smedia\">\n",
      "<li>\n",
      "<a href=\"https://www.facebook.com/webscraperio/\" rel=\"noopener\" target=\"_blank\"><img alt=\"Web Scraper on Facebook\" src=\"/webscraper-python-codedamn-classroom-website/fbicon.png\"/></a>\n",
      "</li>\n",
      "<li>\n",
      "<a href=\"https://twitter.com/webscraperio\" rel=\"noopener\" target=\"_blank\"><img alt=\"Web Scraper on Twitter\" src=\"/webscraper-python-codedamn-classroom-website/twicon.png\"/></a>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-12\">\n",
      "<p class=\"copyright\">\n",
      "\t\t\t\t\t\t\tCopyright © 2020 <a href=\"#\">Web Scraper</a> | All rights reserved |\n",
      "\t\t\t\t\t\t\tRemixed by codedamn\n",
      "\t\t\t\t\t\t</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "print(page_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<!-- Anti-flicker snippet (recommended)  -->\n",
      "<style>\n",
      "\t\t\t.async-hide {\n",
      "\t\t\t\topacity: 0 !important;\n",
      "\t\t\t}\n",
      "\t\t</style>\n",
      "<title>codedamn Web Scraper demo</title>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
      "<meta content=\"web scraping,Web Scraper,Chrome extension,Crawling,Cross platform scraper, \" name=\"keywords\"/>\n",
      "<meta content=\"The most popular web scraping website.\" name=\"description\"/>\n",
      "<link href=\"/webscraper-python-codedamn-classroom-website/favicon.png\" rel=\"icon\" sizes=\"128x128\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<link href=\"/webscraper-python-codedamn-classroom-website/app.css\" rel=\"stylesheet\"/>\n",
      "<link href=\"/webscraper-python-codedamn-classroom-website/logo-icon.png\" rel=\"apple-touch-icon\"/>\n",
      "<script defer=\"\" src=\"/webscraper-python-codedamn-classroom-website/app.js\"></script>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "print(page_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. select with BeautifulSoup\n",
    "\n",
    "Now that we have explored some parts of BeautifulSoup, let us look how we can select DOM elements with BeautifulSoup methods.\n",
    "\n",
    "Once we have the `soup` variable with us (like previous labs), we can work with `.select` on it which is a CSS selector inside BeautifulSoup, i.e., you can reach down the DOM tree just like how you will select elements with CSS. Let us take an example:\n",
    "\n",
    "****\n",
    "\n",
    "```python\n",
    "import requests from bs4 import BeautifulSoup\n",
    "# Make a request\n",
    "page = requests.get(\"URL\")\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Extract first <h1>(...)</h1> text\n",
    "first_h1 = soup.select('h1')[0].text\n",
    "```\n",
    "\n",
    "****\n",
    "\n",
    "`.select` returns you a Python list of all the elements, this is why we selected only the first element here with the `[0]` index.\n",
    "\n",
    "Passing requirements:\n",
    "\n",
    "- Create a variable `all_h1_tags`. Set it to an empty list.\n",
    "- Use `.select` to select all the `<h1>` tags and store the text of those h1 inside `all_h1_tags` list.\n",
    "- Create a variable `seventh_p_text` and store the text of 7th `p` element (index 6) inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test Sites', 'E-commerce training site'] 7 reviews\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Create all_h1_tags as empty list\n",
    "all_h1_tags = []\n",
    "# Set all_h1_tags to all h1 tags of the soup\n",
    "for h1 in soup.select('h1'):\n",
    "    all_h1_tags.append(h1.text)\n",
    "# Create seventh_p_text and set it to 7th p element text of the page\n",
    "seventh_p_text = soup.select('p')[6].text\n",
    "\n",
    "print(all_h1_tags, seventh_p_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Top items being scraped right now\n",
    "\n",
    "Let us go ahead and extract the top items scraped from our URL: https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\n",
    "\n",
    "If you open this page in a new tab, you’ll see some top items. In this lab, your task is to scrape out their names and store them in a list called `top_items`. We will also extract out the reviews for these items as well.\n",
    "\n",
    "To pass this challenge, take care of the following things:\n",
    "\n",
    "- Use `.select` to extract the titles. (Hint: one selector for product titles could be `a.title`)\n",
    "- Use `.select` to extract the review count label for those product titles. (Hint: one selector for reviews could be `div.ratings`) Note: this is a complete label (i.e. **2 reviews**) and not just a number.\n",
    "- Create a new dictionary in the format:\n",
    "\n",
    "****\n",
    "\n",
    "```python\n",
    "info = {\n",
    "   \"title\": 'Asus AsusPro Adv...   '.strip(),\n",
    "   \"review\": '2 reviews\\n\\n\\n'.strip()\n",
    "}\n",
    "```\n",
    "\n",
    "****\n",
    "\n",
    "- Note we are using the `strip` method to remove any extra newlines/whitespaces we might have in the output. This is **important** to pass this lab.\n",
    "- Append this dictionary in a list called `top_items`\n",
    "- Print this list at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Asus AsusPro Adv...', 'review': '7 reviews'}, {'title': 'Asus ROG Strix G...', 'review': '4 reviews'}, {'title': 'Acer Aspire 3 A3...', 'review': '2 reviews'}]\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\n",
    "    \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Create top_items as empty list\n",
    "top_items = []\n",
    "\n",
    "# Extract and store in top_items according to instructions on the left\n",
    "for title, ratings in zip(soup.select('a.title'), soup.select('div.ratings')):\n",
    "    t = title.text.strip()\n",
    "    rating = ratings.select('p.pull-right')[0].text\n",
    "    #print(t, rating)\n",
    "    top_items.append({\"title\": t, \"review\":rating})\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extracting Links\n",
    "\n",
    "So far you have seen how you can extract the text, or rather innerText of elements. Let's now see how you can extract attributes by extracting links from the page.\n",
    "\n",
    "Here’s an example of how to extract out all the image information from the page:\n",
    "****\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Make a request\n",
    "page = requests.get(\n",
    "    \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Create top_items as empty list\n",
    "image_data = []\n",
    "\n",
    "# Extract and store in top_items according to instructions on the left\n",
    "images = soup.select('img')\n",
    "for image in images:\n",
    "    src = image.get('src')\n",
    "    alt = image.get('alt')\n",
    "    image_data.append({\"src\": src, \"alt\": alt})\n",
    "\n",
    "print(image_data)\n",
    "```\n",
    "****\n",
    "In this lab, your task is to extract the `href` attribute of links with their `text` as well. Make sure of the following things:\n",
    "\n",
    "- You have to create a list called `all_links`\n",
    "- In this list, store all link dict information. It should be in the following format:\n",
    "****\n",
    "```python\n",
    "info = {\n",
    "   \"href\": \"<link here>\",\n",
    "   \"text\": \"<link text here>\"\n",
    "}\n",
    "```\n",
    "****\n",
    "- Make sure your `text` is stripped of any whitespace\n",
    "- Make sure you check if your `.text` is None before you call `.strip()` on it.\n",
    "- Store all these dicts in the `all_links`\n",
    "- Print this list at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'href': None, 'text': 'Toggle navigation'}, {'href': '/webscraper-python-codedamn-classroom-website/', 'text': ''}, {'href': '#page-top', 'text': ''}, {'href': '/webscraper-python-codedamn-classroom-website/', 'text': 'Web Scraper'}, {'href': '/webscraper-python-codedamn-classroom-website/cloud-scraper', 'text': 'Cloud Scraper'}, {'href': '/webscraper-python-codedamn-classroom-website/pricing', 'text': 'Pricing'}, {'href': '#section3', 'text': 'Learn'}, {'href': '/webscraper-python-codedamn-classroom-website/documentation', 'text': 'Documentation'}, {'href': '/webscraper-python-codedamn-classroom-website/tutorials', 'text': 'Video Tutorials'}, {'href': '/webscraper-python-codedamn-classroom-website/how-to-videos', 'text': 'How to'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites', 'text': 'Test Sites'}, {'href': 'https://forum.webscraper.io/', 'text': 'Forum'}, {'href': 'https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn?hl=en', 'text': 'Install'}, {'href': 'https://cloud.webscraper.io/', 'text': 'Login'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone', 'text': 'Home'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/computers', 'text': 'Computers'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/phones', 'text': 'Phones'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/593', 'text': 'Asus AsusPro Adv...'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/583', 'text': 'Asus ROG Strix G...'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/576', 'text': 'Acer Aspire 3 A3...'}, {'href': '/webscraper-python-codedamn-classroom-website/', 'text': 'Web Scraper browser extension'}, {'href': '/webscraper-python-codedamn-classroom-website/pricing', 'text': 'Web Scraper Cloud'}, {'href': '/webscraper-python-codedamn-classroom-website/contact', 'text': 'Contact'}, {'href': '/webscraper-python-codedamn-classroom-website/privacy-policy', 'text': 'Website Privacy Policy'}, {'href': '/webscraper-python-codedamn-classroom-website/extension-privacy-policy', 'text': 'Browser Extension Privacy Policy'}, {'href': 'http://webscraperio.us-east-1.elasticbeanstalk.com/downloads/Web_Scraper_Media_Kit.zip', 'text': 'Media kit'}, {'href': '/webscraper-python-codedamn-classroom-website/jobs', 'text': 'Jobs'}, {'href': '/webscraper-python-codedamn-classroom-website/blog', 'text': 'Blog'}, {'href': '/webscraper-python-codedamn-classroom-website/documentation', 'text': 'Documentation'}, {'href': '/webscraper-python-codedamn-classroom-website/tutorials', 'text': 'Video Tutorials'}, {'href': '/webscraper-python-codedamn-classroom-website/screenshots', 'text': 'Screenshots'}, {'href': '/webscraper-python-codedamn-classroom-website/test-sites', 'text': 'Test Sites'}, {'href': 'https://forum.webscraper.io/', 'text': 'Forum'}, {'href': 'mailto:info@webscraper.io', 'text': 'info@webscraper.io'}, {'href': 'https://www.facebook.com/webscraperio/', 'text': ''}, {'href': 'https://twitter.com/webscraperio', 'text': ''}, {'href': '#', 'text': 'Web Scraper'}]\n"
     ]
    }
   ],
   "source": [
    "all_links = []\n",
    "\n",
    "page = requests.get(\n",
    "    \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "for link in soup.select('a'):\n",
    "    href = link.get('href')\n",
    "    text = link.text.strip()\n",
    "    all_links.append({\"href\": href, \"text\": text})\n",
    "\n",
    "print(all_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generating CSV from data\n",
    "\n",
    "Finally, let's understand how you can generate CSV from a set of data. You will create a CSV with the following headings:\n",
    "\n",
    "1. Product Name\n",
    "2. Price\n",
    "3. Description\n",
    "4. Reviews\n",
    "5. Product Image\n",
    "\n",
    "These products are located in the `div.thumbnail`. The CSV boilerplate is given below:\n",
    "\n",
    "****\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "# Make a request\n",
    "page = requests.get(\n",
    "    \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "all_products = []\n",
    "\n",
    "products = soup.select('div.thumbnail')\n",
    "for product in products:\n",
    "    # TODO: Work\n",
    "    print(\"Work on product here\")\n",
    "\n",
    "\n",
    "keys = all_products[0].keys()\n",
    "\n",
    "with open('products.csv', 'w', newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(all_products)\n",
    "```\n",
    "\n",
    "****\n",
    "\n",
    "You have to extract data from the website and generate this CSV for the three products.\n",
    "\n",
    "### Passing Requirements:\n",
    "\n",
    "- Product Name is the whitespace trimmed version of the name of the item (example - Asus AsusPro Adv..)\n",
    "- Price is the whitespace trimmed but full price label of the product (example - $1101.83)\n",
    "- The description is the whitespace trimmed version of the product description (example - Asus AsusPro Advanced BU401LA-FA271G Dark Grey, 14\", Core i5-4210U, 4GB, 128GB SSD, Win7 Pro)\n",
    "- Reviews are the whitespace trimmed version of the product (example - 7 reviews)\n",
    "- Product image is the URL (src attribute) of the image for a product (example - /webscraper-python-codedamn-classroom-website/cart2.png)\n",
    "- The name of the CSV file should be **products.csv** and should be stored in the same directory as your **script.py** file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "# Make a request\n",
    "page = requests.get(\n",
    "    \"https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "all_products = []\n",
    "\n",
    "products = soup.select('div.thumbnail')\n",
    "for product in products:\n",
    "    # TODO: Work\n",
    "    name = product.select('a')[0].get('title').strip()\n",
    "    price = product.select('h4')[0].text.strip()\n",
    "    description = \"\".join([word.strip('\\n') for word in product.select('p.description')[0].text.strip().split('\\t')])\n",
    "    review = product.select('div.ratings')[0].text.strip()\n",
    "    prod_img = product.select('img')[0].get('src')\n",
    "    all_products.append({'Product Name' : name ,\n",
    "                         'Price' : price,\n",
    "                         'Description' : description,\n",
    "                         'Reviews' : review,\n",
    "                         'Product Image' : prod_img})\n",
    "    \n",
    "keys = all_products[0].keys()\n",
    "\n",
    "with open('products.csv', 'w', newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(all_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Product Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus AsusPro Advanced BU401LA-FA271G Dark Grey</td>\n",
       "      <td>$1139.54</td>\n",
       "      <td>Asus AsusPro Advanced BU401LA-FA271G Dark Grey...</td>\n",
       "      <td>7 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asus ROG Strix GL553VD-DM535T</td>\n",
       "      <td>$1101.83</td>\n",
       "      <td>Apple MacBook Air 13.3\", Core i5 1.8GHz, 8GB, ...</td>\n",
       "      <td>4 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Aspire 3 A315-51 Black</td>\n",
       "      <td>$494.71</td>\n",
       "      <td>Acer Aspire 3 A315-51 Black, 15.6\" FHD, Corei3...</td>\n",
       "      <td>2 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Product Name     Price  \\\n",
       "0  Asus AsusPro Advanced BU401LA-FA271G Dark Grey  $1139.54   \n",
       "1                   Asus ROG Strix GL553VD-DM535T  $1101.83   \n",
       "2                     Acer Aspire 3 A315-51 Black   $494.71   \n",
       "\n",
       "                                         Description    Reviews  \\\n",
       "0  Asus AsusPro Advanced BU401LA-FA271G Dark Grey...  7 reviews   \n",
       "1  Apple MacBook Air 13.3\", Core i5 1.8GHz, 8GB, ...  4 reviews   \n",
       "2  Acer Aspire 3 A315-51 Black, 15.6\" FHD, Corei3...  2 reviews   \n",
       "\n",
       "                                       Product Image  \n",
       "0  /webscraper-python-codedamn-classroom-website/...  \n",
       "1  /webscraper-python-codedamn-classroom-website/...  \n",
       "2  /webscraper-python-codedamn-classroom-website/...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Product Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus AsusPro Advanced BU401LA-FA271G Dark Grey</td>\n",
       "      <td>$1139.54</td>\n",
       "      <td>Asus AsusPro Advanced BU401LA-FA271G Dark Grey...</td>\n",
       "      <td>7 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asus ROG Strix GL553VD-DM535T</td>\n",
       "      <td>$1101.83</td>\n",
       "      <td>Apple MacBook Air 13.3\", Core i5 1.8GHz, 8GB, ...</td>\n",
       "      <td>4 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Aspire 3 A315-51 Black</td>\n",
       "      <td>$494.71</td>\n",
       "      <td>Acer Aspire 3 A315-51 Black, 15.6\" FHD, Corei3...</td>\n",
       "      <td>2 reviews</td>\n",
       "      <td>/webscraper-python-codedamn-classroom-website/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Product Name     Price  \\\n",
       "0  Asus AsusPro Advanced BU401LA-FA271G Dark Grey  $1139.54   \n",
       "1                   Asus ROG Strix GL553VD-DM535T  $1101.83   \n",
       "2                     Acer Aspire 3 A315-51 Black   $494.71   \n",
       "\n",
       "                                         Description    Reviews  \\\n",
       "0  Asus AsusPro Advanced BU401LA-FA271G Dark Grey...  7 reviews   \n",
       "1  Apple MacBook Air 13.3\", Core i5 1.8GHz, 8GB, ...  4 reviews   \n",
       "2  Acer Aspire 3 A315-51 Black, 15.6\" FHD, Corei3...  2 reviews   \n",
       "\n",
       "                                       Product Image  \n",
       "0  /webscraper-python-codedamn-classroom-website/...  \n",
       "1  /webscraper-python-codedamn-classroom-website/...  \n",
       "2  /webscraper-python-codedamn-classroom-website/...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_products)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
